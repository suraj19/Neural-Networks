# -*- coding: utf-8 -*-
"""ANN_For_Bank_Data_Using_Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FjKL9TT0N2gGrTP9_B5gc6Y6SG8Ngl3J
"""

''''''
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from google.colab import files
import os
import pandas as pd
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
uploaded = files.upload()

import io
dataset = pd.read_csv(io.BytesIO(uploaded['Bank_Data.csv']))
#dataset=pd.read_csv("Bank_data.csv")
X = dataset.iloc[:,3:13].values
y = dataset.iloc[:,13].values
#dataset.head(3)
X

from sklearn.preprocessing import LabelEncoder,OneHotEncoder
labelencoder_X_1=LabelEncoder()
X[:,1]=labelencoder_X_1.fit_transform(X[:,1])
labelencoder_X_2 =LabelEncoder()
X[:,2]=labelencoder_X_2.fit_transform(X[:,2])
X

onehotencoder = OneHotEncoder(categorical_features=[1])
X=onehotencoder.fit_transform(X).toarray()
X

X= X[:,1:]#To avoid the dummy variable Trap
X

#splitting the data set
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.2,random_state=0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc =StandardScaler()
X_train=sc.fit_transform(X_train)
X_test = sc.transform(X_test)
X_train

import keras
from keras.models import Sequential
from keras.layers import Dense

#Increase in Hidden Layers Decreases the Accuracy as it Overfit the Dataset 
classifier = Sequential()
#Adding the input layer and the first hidden layer
classifier.add(Dense(output_dim =6,init='uniform',activation ='relu',input_dim=11))
#adding the second hidden layer
classifier.add(Dense(output_dim =6,init='uniform',activation ='relu'))
#classifier.add(Dense(output_dim =6,init='uniform',activation ='sigmoid'))
#classifier.add(Dense(output_dim =6,init='uniform',activation ='relu'))
#classifier.add(Dense(output_dim =6,init='uniform',activation ='relu'))

#adding the output layer
classifier.add(Dense(output_dim =1,init='uniform',activation ='sigmoid'))

#compliling the ANN
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
#a gradient descent techinique is used  using the keyword adam
#loss - 
#metrics-

#fitting the ANN to training set
classifier.fit(X_train,y_train,batch_size=10,nb_epoch=100)

#Making the predictions and evaluating the model
#predicting the test reults
y_pred =classifier.predict(X_test)
y_pred = (y_pred>0.5)
y_pred

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
cm

TP = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]
TN = cm[0,0]
Total=TP+TN+FN+FP

Accuracy=(TP+TN)/Total
Accuracy*100

